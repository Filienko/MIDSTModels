{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## White Box Single Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a multi-track competition aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This competition focuses on White Box MIA on tabular diffusion models trained on a single table transaction dataset. The schema of the transaction dataset is as follows:\n",
    "| trans_id | account_id | trans_date | trans_type | operation | amount  | balance  | k_symbol | bank | account |\n",
    "|----------|------------|------------|------------|-----------|---------|----------|----------|------|---------|\n",
    "| integer  | integer    | integer    | integer    | integer   | float   | float    | integer  | integer | integer |\n",
    "\n",
    "MIA will be performed over two state-of-the-art methods [TabSyn](https://arxiv.org/pdf/2310.09656) and [TabDDPM](https://arxiv.org/pdf/2209.15421). A collection of TabSyn and TabDDPM models will be trained on random subsets of the transaction dataset. The goal is to create an approach (MIA) that can distinguish between samples used to train a model (train data) and other data randomly sampled from the transaction dataset (holdout data) given the model and it's output synthetic data. The `final` set includes 20 models, each with its own set of challenge points (ie train and holdout data), to evaluate solutions on. To facilitate designing an attack, 30 `train` models are provided with comprehensive information about the model, training data and output synthetic data. Additionally, 20 `dev` models are provided to assist in evaluating the effectiveness of attacks prior to making a final submission to the `final` set. Participants can choose to perform MIA over one of or both TabSyn and TabDDPM. In the case of both, the attack that obtains the highest score will be used to rank the submission. A high level summary of the competition is below:\n",
    "![wbox_diagram_final](https://github.com/user-attachments/assets/2ebb5eed-a6e3-433a-8769-4310b7fbc822)\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box single table challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "Ensure that you have installed the proper dependenices to run the notebook. The environment installation instructions are available [here](https://github.com/VectorInstitute/MIDSTModels/tree/main/starter_kits). Now that we have verfied we have the proper packages installed, lets import them and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from data import get_challenge_points\n",
    "from metrics import get_tpr_at_fpr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ksush\\attacks\\MIDSTModels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksush\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midst_models.single_table_TabDDPM.complex_pipeline import tabddpm_whitebox_load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "TABDDPM_DATA_DIR = \"tabddpm_white_box\"\n",
    "TABSYN_DATA_DIR = \"tabsyn_white_box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_FLAGS():\n",
    "    def FLAGS(x): return x\n",
    "    FLAGS.T = 1000\n",
    "    FLAGS.ch = 128\n",
    "    FLAGS.ch_mult = [1, 2, 2, 2]\n",
    "    FLAGS.attn = [1]\n",
    "    FLAGS.num_res_blocks = 2\n",
    "    FLAGS.dropout = 0.1\n",
    "    FLAGS.beta_1 = 0.0001\n",
    "    FLAGS.beta_T = 0.02\n",
    "\n",
    "    return FLAGS\n",
    "\n",
    "FLAGS = get_FLAGS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "import csv\n",
    "import os\n",
    "from typing import Dict, Type\n",
    "from torch.nn.functional import normalize\n",
    "import midst_models.attack.components as components\n",
    "\n",
    "class EpsGetter(components.EpsGetter):\n",
    "    def __call__(self, xt: torch.Tensor, condition: torch.Tensor = None, noise_level=None, t: int = None) -> torch.Tensor:\n",
    "        # Access the diffusion model from the dictionary structure\n",
    "        model = self.model[(None, 'trans')]['diffusion']\n",
    "\n",
    "        t = torch.ones([xt.shape[0]], device=xt.device).long() * t\n",
    "        return model._denoise_fn(xt, timesteps=t)\n",
    "\n",
    "ATTACKERS: Dict[str, Type[components.DDIMAttacker]] = {\n",
    "    \"PIA\": components.PIA,\n",
    "    \"PIAN\": components.PIAN,\n",
    "}\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def attack(base_dir, attacker_name=\"PIA\", attack_num=30, interval=10, seed=0):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # logger.addHandler(RichHandler())\n",
    "\n",
    "    logger.info(\"loading the attacked model...\")\n",
    "\n",
    "    # Initialize attacker\n",
    "    phases = [\"train\"]\n",
    "    \n",
    "    logger.info(\"attack start...\")\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "            if model_folder.endswith(\"30\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                print(\"path\",path)\n",
    "                model = tabddpm_whitebox_load_pretrained(path)\n",
    "                attacker = ATTACKERS[attacker_name](\n",
    "                    torch.from_numpy(np.linspace(FLAGS.beta_1, FLAGS.beta_T, FLAGS.T)).to(DEVICE), interval, attack_num, EpsGetter(model), lp=4)\n",
    "\n",
    "                # Move the points to GPU\n",
    "                challenge_points = get_challenge_points(path)\n",
    "\n",
    "                # Get raw predictions\n",
    "                raw_predictions = torch.stack([attacker(cp.to(DEVICE).float()) for cp in challenge_points])\n",
    "\n",
    "                # Convert to binary predictions based on membership\n",
    "                # First normalize the predictions to [0,1] range\n",
    "                normalized_preds = []\n",
    "                for pred_batch in raw_predictions:\n",
    "                    # Handle each prediction batch separately\n",
    "                    batch_min = pred_batch.min()\n",
    "                    batch_max = pred_batch.max()\n",
    "                    \n",
    "                    # Avoid division by zero if all predictions are the same\n",
    "                    if batch_max == batch_min:\n",
    "                        normalized = torch.zeros_like(pred_batch)\n",
    "                    else:\n",
    "                        normalized = (pred_batch - batch_min) / (batch_max - batch_min)\n",
    "                    \n",
    "                    # Convert to binary predictions using 0.5 as threshold\n",
    "                    binary_preds = (normalized >= 0.5).float()\n",
    "                    normalized_preds.append(binary_preds)\n",
    "                \n",
    "                # Stack all normalized predictions\n",
    "                final_predictions = torch.stack(normalized_preds)\n",
    "                predictions_cpu = final_predictions.cpu().detach().numpy()\n",
    "                \n",
    "                # Verify predictions are binary (0 or 1)\n",
    "                assert np.all(np.logical_or(predictions_cpu == 0, predictions_cpu == 1)), \"Predictions are not binary\"\n",
    "                \n",
    "                # Write predictions to file\n",
    "                with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    # Write each value in a separate row\n",
    "                    for value in predictions_cpu.squeeze():\n",
    "                        writer.writerow([value])\n",
    "\n",
    "                # Optional logging of sample predictions\n",
    "                print(f\"raw_predictions.shape: {raw_predictions.shape}\")\n",
    "                print(f\"Sample binary predictions: {predictions_cpu.squeeze()[:5]}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path tabddpm_white_box\\train\\tabddpm_30\n",
      "Checkpoint found, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksush\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ksush\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator QuantileTransformer from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_predictions.shape: torch.Size([200, 2, 8])\n",
      "Sample binary predictions: [[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "attack(base_dir=\"tabddpm_white_box\",\n",
    "        attacker_name=\"PIA\",\n",
    "        attack_num=2,\n",
    "        interval=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final` in `tabddpm_white_box` and `tabsyn_white_box`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaBench.**\n",
    "\n",
    "In the following, we will show you how to correctly package a submission to the competition. To focus solely on the submission logic, the attack model will simply generate random predictions. Let's start by creating baseline attack models `tabddpm_attack_model` and `tabsyn_attack_model` based on their respective shadow models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "def get_attack_model(base_train_path: Path) -> Callable[[Any], float]:\n",
    "    return lambda x : random.uniform(0, 1)\n",
    "\n",
    "base_tabddpm_train_path = os.path.join(TABDDPM_DATA_DIR, \"train\")\n",
    "base_tabsyn_train_path = os.path.join(TABSYN_DATA_DIR, \"train\")\n",
    "tabddpm_attack_model = get_attack_model(base_tabddpm_train_path)\n",
    "tabsyn_attack_model = get_attack_model(base_tabsyn_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the attack model, we can obtain predictions for each point in the challenge point set for train, dev and final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [],
   "source": [
    "phases = [\"train\", \"dev\", \"final\"]\n",
    "\n",
    "for base_dir, attack_model in zip([TABDDPM_DATA_DIR, TABSYN_DATA_DIR], [tabddpm_attack_model, tabsyn_attack_model]):\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "    \n",
    "            challenge_points = get_challenge_points(path)\n",
    "    \n",
    "            predictions = torch.Tensor([attack_model(cp) for cp in challenge_points])\n",
    "           \n",
    "            assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "            with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "    \n",
    "                # Write each value in a separate row\n",
    "                for value in list(predictions.numpy().squeeze()):\n",
    "                    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '\"[[0.' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '\"[[0.'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_folder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(root), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m d: \u001b[38;5;28mint\u001b[39m(d\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m      8\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, model_folder)\n\u001b[1;32m----> 9\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m     solutions\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mloadtxt(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchallenge_label.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(predictions)  \u001b[38;5;66;03m# Shape: [N_points, 3]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\_npyio_impl.py:1381\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1379\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1381\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\_npyio_impl.py:1021\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1021\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string '\"[[0.' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def get_tpr_at_fpr(y_true, y_score, target_fpr=0.1):\n",
    "    \"\"\"Calculate TPR at a specific FPR threshold.\"\"\"\n",
    "    # Sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n",
    "    y_score = y_score[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "    \n",
    "    # Calculate cumulative FPR and TPR\n",
    "    n_neg = np.sum(y_true == 0)\n",
    "    n_pos = np.sum(y_true == 1)\n",
    "    tpr = np.cumsum(y_true) / n_pos\n",
    "    fpr = np.cumsum(1 - y_true) / n_neg\n",
    "    \n",
    "    # Find TPR at target FPR\n",
    "    for i in range(len(fpr)):\n",
    "        if fpr[i] >= target_fpr:\n",
    "            return tpr[i]\n",
    "    return 1.0\n",
    "\n",
    "def evaluate_predictions(base_dirs, num_attackers=2):\n",
    "    tpr_at_fpr_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    for base_dir in base_dirs:\n",
    "        predictions = []\n",
    "        solutions = []\n",
    "        root = os.path.join(base_dir, \"train\")\n",
    "        \n",
    "        for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            \n",
    "            # Load predictions - reshape to account for multiple attackers\n",
    "            pred = np.loadtxt(os.path.join(path, \"prediction.csv\"))\n",
    "            pred = pred.reshape(-1, num_attackers, 8)  # [N_points, num_attackers, 8]\n",
    "            \n",
    "            # Average predictions across attackers\n",
    "            pred_mean = np.mean(pred, axis=1)  # [N_points, 8]\n",
    "            predictions.append(pred_mean)\n",
    "            \n",
    "            # Load ground truth\n",
    "            solution = np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1)\n",
    "            solutions.append(solution)\n",
    "        \n",
    "        predictions = np.concatenate(predictions)  # Shape: [N_total_points, 8]\n",
    "        solutions = np.concatenate(solutions)      # Shape: [N_total_points]\n",
    "        \n",
    "        # Calculate metrics for each dimension\n",
    "        for dim in range(predictions.shape[1]):\n",
    "            dim_preds = predictions[:, dim]\n",
    "            \n",
    "            # Calculate TPR at FPR\n",
    "            tpr_at_fpr = get_tpr_at_fpr(solutions, dim_preds)\n",
    "            tpr_at_fpr_list.append(tpr_at_fpr)\n",
    "            \n",
    "            # Calculate AUC\n",
    "            auc = roc_auc_score(solutions, dim_preds)\n",
    "            auc_list.append(auc)\n",
    "            \n",
    "            print(f\"{os.path.basename(base_dir)} Train Attack Dimension {dim}:\")\n",
    "            print(f\"  TPR at FPR==10%: {tpr_at_fpr:.4f}\")\n",
    "            print(f\"  AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Get best scores across all dimensions\n",
    "    final_tpr_at_fpr = max(tpr_at_fpr_list)\n",
    "    final_auc = max(auc_list)\n",
    "    \n",
    "    print(f\"\\nBest scores across dimensions:\")\n",
    "    print(f\"Final Train Attack TPR at FPR==10%: {final_tpr_at_fpr:.4f}\")\n",
    "    print(f\"Final Train Attack AUC: {final_auc:.4f}\")\n",
    "    \n",
    "    return final_tpr_at_fpr, final_auc\n",
    "\n",
    "# Example usage\n",
    "base_dirs = [TABDDPM_DATA_DIR]  # Add TABSYN_DATA_DIR if needed\n",
    "final_tpr, final_auc = evaluate_predictions(base_dirs, num_attackers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench. Importantly, we create a single zip file for dev and final. The structure of the submission is as follows:\n",
    "\n",
    "```\n",
    "└── root_folder\n",
    "    ├── tabsyn_white_box\n",
    "    │   ├── dev\n",
    "    │   │   └── tabsyn_#\n",
    "    │   │       └── prediction.csv\n",
    "    │   └── final\n",
    "    │       └── tabsyn_#\n",
    "    │           └── prediction.csv\n",
    "    └── tabddpm_white_box\n",
    "        ├── dev \n",
    "        │   └── tabddpm_#\n",
    "        │       └── prediction.csv\n",
    "        └── final \n",
    "            └── tabddpm_# \n",
    "                └── prediction.csv\n",
    "```\n",
    "**Note:** The `root_folder` can have any name but it is important all of the subdirectories follow the above structure and naming conventions. \n",
    "\n",
    "If a participant is looking to submit an attack for only one of TabSyn and TabDDPM, they can simply omit the other directory (ie `tabddpm_white_box` or `tabsyn_white_box` from the root_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f\"white_box_single_table_submission.zip\", 'w') as zipf:\n",
    "    for phase in [\"dev\", \"final\"]:\n",
    "        for base_dir in [TABDDPM_DATA_DIR, TABSYN_DATA_DIR]:\n",
    "            root = os.path.join(base_dir, phase)\n",
    "            for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                if not os.path.isdir(path): continue\n",
    "\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    # Use `arcname` to remove the base directory and phase directory from the zip path\n",
    "                    arcname = os.path.relpath(file, os.path.dirname(base_dir))\n",
    "                    zipf.write(file, arcname=arcname)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated white_box_single_table_submission.zip can be directly submitted to the dev phase in the CodaBench UI. Although this submission contains your predictions for both the dev and final set, you will only receive feedback on your predictions for the dev phase. The predictions for the final phase will be evaluated once the competiton ends using the most recent submission to the dev phase."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
