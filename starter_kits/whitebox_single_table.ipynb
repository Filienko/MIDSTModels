{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## White Box Single Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a multi-track competition aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This competition focuses on White Box MIA on tabular diffusion models trained on a single table transaction dataset. The schema of the transaction dataset is as follows:\n",
    "| trans_id | account_id | trans_date | trans_type | operation | amount  | balance  | k_symbol | bank | account |\n",
    "|----------|------------|------------|------------|-----------|---------|----------|----------|------|---------|\n",
    "| integer  | integer    | integer    | integer    | integer   | float   | float    | integer  | integer | integer |\n",
    "\n",
    "MIA will be performed over two state-of-the-art methods [TabSyn](https://arxiv.org/pdf/2310.09656) and [TabDDPM](https://arxiv.org/pdf/2209.15421). A collection of TabSyn and TabDDPM models will be trained on random subsets of the transaction dataset. The goal is to create an approach (MIA) that can distinguish between samples used to train a model (train data) and other data randomly sampled from the transaction dataset (holdout data) given the model and it's output synthetic data. The `final` set includes 20 models, each with its own set of challenge points (ie train and holdout data), to evaluate solutions on. To facilitate designing an attack, 30 `train` models are provided with comprehensive information about the model, training data and output synthetic data. Additionally, 20 `dev` models are provided to assist in evaluating the effectiveness of attacks prior to making a final submission to the `final` set. Participants can choose to perform MIA over one of or both TabSyn and TabDDPM. In the case of both, the attack that obtains the highest score will be used to rank the submission. A high level summary of the competition is below:\n",
    "![wbox_diagram_final](https://github.com/user-attachments/assets/2ebb5eed-a6e3-433a-8769-4310b7fbc822)\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box single table challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midst_models.single_table_TabDDPM.complex_pipeline import (\n",
    "    clava_clustering,\n",
    "    clava_training,\n",
    "    clava_load_pretrained,\n",
    "    clava_synthesizing,\n",
    "    load_configs,\n",
    "    clava_attacking\n",
    ")\n",
    "from midst_models.single_table_TabDDPM.pipeline_modules import load_multi_table\n",
    "from midst_models.single_table_TabDDPM.complex_pipeline import tabddpm_whitebox_load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Type\n",
    "import midst_models.attack.components as components\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class EpsGetter(components.EpsGetter):\n",
    "    def __call__(self, xt: torch.Tensor, condition: torch.Tensor = None, noise_level=None, t: int = None) -> torch.Tensor:\n",
    "        # Access the diffusion model from the dictionary structure\n",
    "        model = self.model\n",
    "\n",
    "        t = torch.ones([xt.shape[0]], device=xt.device).long() * t\n",
    "        return model(xt, timesteps=t)\n",
    "\n",
    "ATTACKERS: Dict[str, Type[components.DDIMAttacker]] = {\n",
    "    \"PIA\": components.PIA,\n",
    "    \"PIAN\": components.PIAN,\n",
    "}\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def get_FLAGS():\n",
    "    def FLAGS(x): return x\n",
    "    FLAGS.T = 50000\n",
    "    FLAGS.ch = 128\n",
    "    FLAGS.ch_mult = [1, 2, 2, 2]\n",
    "    FLAGS.attn = [1]\n",
    "    FLAGS.num_res_blocks = 2\n",
    "    FLAGS.dropout = 0.01\n",
    "    FLAGS.beta_1 = 0.0001\n",
    "    FLAGS.beta_T = 0.02\n",
    "\n",
    "    return FLAGS\n",
    "\n",
    "FLAGS = get_FLAGS()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"c:/Users/ksush/attacks/MIDSTModels/tabddpm_white_box/final/tabddpm_41\"\n",
    "# model = tabddpm_whitebox_load_pretrained(path)\n",
    "\n",
    "# # Load config\n",
    "# config_path = \"c:/Users/ksush/attacks/MIDSTModels/tabddpm_white_box/final/tabddpm_41/trans.json\"\n",
    "# configs, save_dir = load_configs(config_path)\n",
    "# # os.chdir(path)\n",
    "\n",
    "# # Display config\n",
    "# json_str = json.dumps(configs, indent=4)\n",
    "# print(json_str)\n",
    "\n",
    "# # Load  dataset\n",
    "# # In this step, we load the dataset according to the 'dataset_meta.json' file located in the data_dir.\n",
    "# tables, relation_order, dataset_meta = load_multi_table(path, train_data=\"challenge\")\n",
    "\n",
    "# # Tables is a dictionary of the multi-table dataset\n",
    "# print(\n",
    "#     \"{} We show the keys of the tables dictionary below {}\".format(\"=\" * 20, \"=\" * 20)\n",
    "# )\n",
    "# print(list(tables.keys()))\n",
    "\n",
    "\n",
    "# # Display important clustering parameters\n",
    "# params_clustering = configs[\"clustering\"]\n",
    "# print(\"{} We show the clustering parameters below {}\".format(\"=\" * 20, \"=\" * 20))\n",
    "# for key, val in params_clustering.items():\n",
    "#     print(f\"{key}: {val}\")\n",
    "# print(\"\")\n",
    "\n",
    "# # Clustering on the multi-table dataset\n",
    "# tables, all_group_lengths_prob_dicts = clava_clustering(\n",
    "#     tables, relation_order, save_dir, configs\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate synthetic data from scratch\n",
    "# cleaned_tables, synthesizing_time_spent, matching_time_spent = clava_synthesizing(\n",
    "#     tables,\n",
    "#     relation_order,\n",
    "#     save_dir,\n",
    "#     all_group_lengths_prob_dicts,\n",
    "#     model,\n",
    "#     configs,\n",
    "#     # sample_scale=1 if \"debug\" not in configs else configs[\"debug\"][\"sample_scale\"],\n",
    "#     sample_scale=1.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def remove_first_two_columns(input_csv, output_csv):\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(input_csv)\n",
    "    \n",
    "#     # Drop the first two columns\n",
    "#     df = df.drop(df.columns[:2], axis=1)\n",
    "    \n",
    "#     # Save the modified DataFrame to a new CSV file\n",
    "#     df.to_csv(output_csv, index=False)\n",
    "\n",
    "# # Example usage:\n",
    "# input_csv = r'c:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\dev\\tabddpm_31\\challenge_with_id.csv'  # Path to the input CSV file\n",
    "# output_csv = r'c:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\dev\\tabddpm_31\\challenge.csv'  # Path to save the modified CSV file\n",
    "# remove_first_two_columns(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def process_tabddpm_folders(base_path, attacker_name=\"PIA\", interval=200, attack_num=1):\n",
    "    \"\"\"\n",
    "    Processes all 'tabddpm_{n}' folders inside the given base path.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): The base directory containing 'tabddpm_{n}' folders.\n",
    "    \"\"\"\n",
    "    # Find all folders matching the pattern 'tabddpm_{n}'\n",
    "    tabddpm_folders = glob.glob(os.path.join(base_path, \"tabddpm_*\"))\n",
    "\n",
    "    for path in tabddpm_folders:\n",
    "        print(f\"\\nProcessing folder: {path}\")\n",
    "\n",
    "        # Load pretrained model\n",
    "        model = tabddpm_whitebox_load_pretrained(path)\n",
    "        model = model[(None, 'trans')]['diffusion']._denoise_fn\n",
    "\n",
    "        # Load config\n",
    "        config_path = os.path.join(path, \"trans.json\")\n",
    "        configs, save_dir = load_configs(config_path)\n",
    "\n",
    "        # Display config\n",
    "        print(\"\\n===== Configurations =====\")\n",
    "        print(json.dumps(configs, indent=4))\n",
    "\n",
    "        # Load dataset\n",
    "        tables, relation_order, dataset_meta = load_multi_table(path, train_data=\"challenge\")\n",
    "\n",
    "        # Display table keys\n",
    "        print(\"\\n===== Table Keys =====\")\n",
    "        print(list(tables.keys()))\n",
    "\n",
    "        # Display clustering parameters\n",
    "        params_clustering = configs[\"clustering\"]\n",
    "        print(\"\\n===== Clustering Parameters =====\")\n",
    "        for key, val in params_clustering.items():\n",
    "            print(f\"{key}: {val}\")\n",
    "\n",
    "        # Perform clustering\n",
    "        tables, all_group_lengths_prob_dicts = clava_clustering(\n",
    "            tables, relation_order, save_dir, configs\n",
    "        )\n",
    "\n",
    "        print(f\"Finished processing {path}\\n\" + \"=\" * 50)\n",
    "        attacker = ATTACKERS[attacker_name](\n",
    "            torch.from_numpy(np.linspace(FLAGS.beta_1, FLAGS.beta_T, FLAGS.T)).to(DEVICE), interval, attack_num, EpsGetter(model), None, lp=4)\n",
    "\n",
    "        # Launch training from scratch\n",
    "        clava_attacking(tables, relation_order, path, configs, attacker, model)\n",
    "\n",
    "        # # Generate synthetic data from scratch\n",
    "        # clava_synthesizing(\n",
    "        #     tables,\n",
    "        #     relation_order,\n",
    "        #     save_dir,\n",
    "        #     all_group_lengths_prob_dicts,\n",
    "        #     model,\n",
    "        #     configs,\n",
    "        #     # sample_scale=1 if \"debug\" not in configs else configs[\"debug\"][\"sample_scale\"],\n",
    "        #     sample_scale=1.0,\n",
    "        #     save_distances=path,\n",
    "        #     attacker=attacker\n",
    "        # )\n",
    "\n",
    "        # print(\"Finished performing the MIA\")\n",
    "\n",
    "\n",
    "# Define base directories\n",
    "train_base = r\"C:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\train\"\n",
    "dev_base = r\"C:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\dev\"\n",
    "final_base = r\"C:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\final\"\n",
    "\n",
    "# Process all tabddpm folders in dev and final\n",
    "process_tabddpm_folders(train_base, interval=2, attack_num=3, attacker_name=\"PIAN\", )\n",
    "# process_tabddpm_folders(dev_base, interval=10, attack_num=1, attacker_name=\"PIA\", )\n",
    "# process_tabddpm_folders(final_base, interval=10, attack_num=1, attacker_name=\"PIA\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabddpm_whitebox_load_pretrained(\"c:/Users/ksush/attacks/MIDSTModels/tabddpm_white_box/final/tabddpm_41\")\n",
    "model[None, 'trans']['dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save MIA outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryROC\n",
    "\n",
    "def normalize_scores(member_distances, nonmember_distances):\n",
    "    # If the distances are 2D tensors, take mean along dimension 1\n",
    "    if len(member_distances.shape) > 1:\n",
    "        member_distances = member_distances.mean(dim=1)\n",
    "    if len(nonmember_distances.shape) > 1:\n",
    "        nonmember_distances = nonmember_distances.mean(dim=1)\n",
    "    \n",
    "    max_dist = max(member_distances.max().item(), nonmember_distances.max().item())\n",
    "    member_probs = 1 - (member_distances / max_dist)\n",
    "    nonmember_probs = 1 - (nonmember_distances / max_dist)\n",
    "    return member_probs, nonmember_probs\n",
    "\n",
    "def process_saved_distances(base_path):\n",
    "    results = []\n",
    "    auc_values = []  # List to store AUC values for each folder\n",
    "    roc_values = []  # List to store ROC values for each folder\n",
    "    \n",
    "    tabddpm_folders = glob.glob(os.path.join(base_path, \"tabddpm_*\"))\n",
    "    \n",
    "    for path in tabddpm_folders:\n",
    "        print(f\"\\nProcessing folder: {path}\")\n",
    "        \n",
    "        distances_path = os.path.join(path, \"train_saved_outputs_new_distances.pth\")\n",
    "        if not os.path.exists(distances_path):\n",
    "            print(f\"Skipped {path} - distances file not found.\")\n",
    "            continue\n",
    "        \n",
    "        distances_0_200 = torch.load(distances_path)\n",
    "        \n",
    "        # Stack the tensors if they're not already stacked\n",
    "        if isinstance(distances_0_200, list):\n",
    "            distances_0_200 = torch.stack(distances_0_200)\n",
    "        \n",
    "        label_path = os.path.join(path, \"challenge_label.csv\")\n",
    "        if os.path.exists(label_path):\n",
    "            label_df = pd.read_csv(label_path)\n",
    "            labels = label_df.iloc[:, 0].values\n",
    "            members = labels == 1\n",
    "            non_members = labels == 0\n",
    "            \n",
    "            member_scores, nonmember_scores = normalize_scores(distances_0_200[members], distances_0_200[non_members])\n",
    "            scores = torch.cat([member_scores, nonmember_scores])\n",
    "            \n",
    "            # Convert to NumPy for saving\n",
    "            scores_np = scores.numpy()\n",
    "            pd.DataFrame(scores_np).to_csv(os.path.join(path, \"prediction.csv\"), index=False, header=False)\n",
    "            \n",
    "            # Store the averaged scores\n",
    "            results.append(scores)\n",
    "            \n",
    "            # Calculate AUROC\n",
    "            auroc = BinaryAUROC()(scores, torch.cat([torch.ones_like(member_scores), \n",
    "                                                    torch.zeros_like(nonmember_scores)]).long()).item()\n",
    "            auc_values.append(auroc)\n",
    "            \n",
    "            roc = BinaryROC()(scores, torch.cat([torch.ones_like(member_scores), \n",
    "                                               torch.zeros_like(nonmember_scores)]).long())\n",
    "            \n",
    "            fpr, tpr, _ = roc\n",
    "            fpr_threshold = 0.1\n",
    "            tpr_at_1_fpr = tpr[(fpr < fpr_threshold).sum() - 1].item()\n",
    "            \n",
    "            print(f\"Folder: {path}\")\n",
    "            print(f\"AUROC: {auroc:.4f}\")\n",
    "            print(f\"TPR at 10% FPR: {tpr_at_1_fpr:.4f}\")\n",
    "            roc_values.append(tpr_at_1_fpr)\n",
    "        else:\n",
    "            print(f\"No labels found for {path}, processing distances without AUROC.\")\n",
    "            scores, _ = normalize_scores(distances_0_200, distances_0_200)\n",
    "            scores_np = scores.numpy()\n",
    "            results.append(scores)\n",
    "            pd.DataFrame(scores_np).to_csv(os.path.join(path, \"prediction.csv\"), index=False, header=False)\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    # Calculate the average AUC after all runs\n",
    "    if auc_values:\n",
    "        avg_auc = sum(auc_values) / len(auc_values)\n",
    "        avg_roc = sum(roc_values) / len(roc_values)\n",
    "        print(f\"\\nAverage TPR at 10% FPR: {avg_roc:.4f}\")\n",
    "        print(f\"\\nAverage AUROC: {avg_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo AUC values calculated.\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_results = process_saved_distances(train_base)\n",
    "# dev_results = process_saved_distances(dev_base)\n",
    "# final_results = process_saved_distances(final_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryROC\n",
    "\n",
    "# Distance function\n",
    "def distance(x0, x1, lp=2):\n",
    "    return ((x0 - x1).abs()**lp).flatten(1).sum(dim=-1)\n",
    "\n",
    "# Normalize distances to [0,1] range for probability scores\n",
    "def normalize_scores(member_distances, nonmember_distances):\n",
    "    max_dist = max(member_distances.max().item(), nonmember_distances.max().item())\n",
    "    member_probs = 1 - (member_distances / max_dist)\n",
    "    nonmember_probs = 1 - (nonmember_distances / max_dist)\n",
    "    return member_probs, nonmember_probs\n",
    "\n",
    "def process_saved_outputs(base_path):\n",
    "    \"\"\"\n",
    "    Processes 'saved_outputs_0_200_1000.pth' in each 'tabddpm_{n}' folder inside the given base path,\n",
    "    calculates AUROC, TPR at 10% FPR, and saves the predictions in 'predictions.csv'.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): The base directory containing 'tabddpm_{n}' folders.\n",
    "    \"\"\"\n",
    "    # Find all folders matching the pattern 'tabddpm_{n}'\n",
    "    tabddpm_folders = glob.glob(os.path.join(base_path, \"tabddpm_*\"))\n",
    "\n",
    "    for path in tabddpm_folders:\n",
    "        print(f\"\\nProcessing folder: {path}\")\n",
    "\n",
    "        # Load saved_outputs from the folder\n",
    "        saved_outputs_path = os.path.join(path, \"saved_outputs_0_200_1000.pth\")\n",
    "        if not os.path.exists(saved_outputs_path):\n",
    "            print(f\"Skipped {path} - saved_outputs file not found.\")\n",
    "            continue\n",
    "        \n",
    "        saved_outputs = torch.load(saved_outputs_path)\n",
    "\n",
    "        # Check for challenge labels\n",
    "        label_path = os.path.join(path, \"challenge_label.csv\")\n",
    "        if os.path.exists(label_path):\n",
    "            label_df = pd.read_csv(label_path)\n",
    "            labels = label_df.iloc[:, 0].values  # Convert to numpy array\n",
    "            members = labels == 1\n",
    "            non_members = labels == 0\n",
    "\n",
    "            # Compute distances for T = 0 vs 1000 and T = 0 vs 200\n",
    "            distances_0_1000 = distance(saved_outputs[0], saved_outputs[1000])\n",
    "\n",
    "            distances_0_200 = distance(saved_outputs[0], saved_outputs[200])\n",
    "\n",
    "            # Normalize distances and compute scores\n",
    "            member_scores, nonmember_scores = normalize_scores(distances_0_200[members], distances_0_200[non_members])\n",
    "\n",
    "            # Create labels (1 for members, 0 for non-members)\n",
    "            scores = torch.cat([member_scores, nonmember_scores])\n",
    "            labels = torch.cat([torch.ones_like(member_scores), torch.zeros_like(nonmember_scores)]).long()\n",
    "\n",
    "            # Compute predictions\n",
    "            predictions = (scores).long()\n",
    "\n",
    "            # Save predictions and scores to CSV\n",
    "            predictions_df = pd.DataFrame({'score': scores.numpy()})\n",
    "            predictions_df.to_csv(os.path.join(path, \"predictions.csv\"), index=False, header=False)\n",
    "\n",
    "            # Compute AUROC\n",
    "            auroc = BinaryAUROC()(scores, labels).item()\n",
    "\n",
    "            # Compute ROC curve\n",
    "            roc = BinaryROC()(scores, labels)\n",
    "            fpr, tpr, _ = roc  # Unpack outputs\n",
    "\n",
    "            # Extract TPR at 10% FPR\n",
    "            fpr_threshold = 0.1\n",
    "            tpr_at_1_fpr = tpr[(fpr < fpr_threshold).sum() - 1].item()\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Folder: {path}\")\n",
    "            print(f\"AUROC: {auroc:.4f}\")\n",
    "            print(f\"TPR at 10% FPR: {tpr_at_1_fpr:.4f}\")\n",
    "            print(f\"Predictions saved to {os.path.join(path, 'predictions.csv')}\")\n",
    "        else:\n",
    "            # If challenge_label.csv is not found, just save the predictions based on the available outputs\n",
    "            print(f\"No labels found for {path}, saving predictions without AUROC.\")\n",
    "            distances_0_200 = distance(saved_outputs[0], saved_outputs[200])\n",
    "            # print(f\"Distances 0 vs 1000: {distances_0_200.shape} from {saved_outputs[0].shape} and {saved_outputs[200].shape}\")\n",
    "\n",
    "            # Normalize and save predictions\n",
    "            member_scores, nonmember_scores = normalize_scores(distances_0_200, distances_0_200)  # No label distinction\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            scores = torch.cat([member_scores])\n",
    "            predictions_df = pd.DataFrame({'score': scores.numpy()})\n",
    "            predictions_df.to_csv(os.path.join(path, \"predictions.csv\"), index=False, header=False)\n",
    "\n",
    "            print(f\"Predictions [{predictions_df.shape}] saved to {os.path.join(path, 'predictions.csv')}\")\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "\n",
    "# Define base directories for dev and final\n",
    "dev_base = r\"C:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\dev\"\n",
    "final_base = r\"C:\\Users\\ksush\\attacks\\MIDSTModels\\tabddpm_white_box\\final\"\n",
    "\n",
    "# Process all saved_outputs in dev and final\n",
    "process_saved_outputs(dev_base)\n",
    "process_saved_outputs(final_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "saved_outputs = torch.load(\"saved_outputs_0_200_1000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample distance function\n",
    "def distance(x0, x1, lp=2):\n",
    "    return ((x0 - x1).abs()**lp).flatten(1).sum(dim=-1)\n",
    "\n",
    "\n",
    "# Graph A: Amount of noise predicted per point at different values of T\n",
    "x_values = sorted(saved_outputs.keys())\n",
    "y_values = [saved_outputs[t].abs().mean(dim=1).mean().item() for t in x_values]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-', label='Avg. Noise per Point')\n",
    "plt.xlabel(\"T values\")\n",
    "plt.ylabel(\"Average Noise\")\n",
    "plt.title(\"Noise Predicted per Point across Different T Values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Graph B: Distance between T=0 & T=1000 and T=0 & T=200\n",
    "distances_0_1999 = distance(saved_outputs[0], saved_outputs[1999])\n",
    "distances_0_1800= distance(saved_outputs[0], saved_outputs[1800])\n",
    "distances_0_1600 = distance(saved_outputs[0], saved_outputs[1600])\n",
    "distances_0_1400 = distance(saved_outputs[0], saved_outputs[1400])\n",
    "distances_0_1200 = distance(saved_outputs[0], saved_outputs[1200])\n",
    "distances_0_1000 = distance(saved_outputs[0], saved_outputs[1000])\n",
    "distances_0_800 = distance(saved_outputs[0], saved_outputs[800])\n",
    "distances_0_600 = distance(saved_outputs[0], saved_outputs[600])\n",
    "distances_0_400 = distance(saved_outputs[0], saved_outputs[400])\n",
    "distances_0_200 = distance(saved_outputs[0], saved_outputs[200])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_1999.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=1999)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# TODO: repeat for other values of T\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_1800.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=1800)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_1600.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=1600)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_1400.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=1400)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_1000.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=1000)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_800.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=800)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_600.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=600)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(distances_0_400.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=400)')\n",
    "plt.hist(distances_0_200.numpy(), bins=50, alpha=0.6, label='Dist(T=0, T=200)')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Distances between Noise Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "saved_outputs = torch.load(\"saved_outputs_0_200_1000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Distance function\n",
    "def distance(x0, x1, lp=2):\n",
    "    return ((x0 - x1).abs()**lp).flatten(1).sum(dim=-1)\n",
    "label_df = pd.read_csv(\"tabddpm_white_box/train/tabddpm_1/challenge_label.csv\")\n",
    "\n",
    "# Assume saved_outputs is your dictionary with noise tensors\n",
    "# Assume label_df is a DataFrame with one column containing 1 (member) or 0 (non-member)\n",
    "labels = label_df.iloc[:, 0].values  # Convert to numpy array\n",
    "\n",
    "# Separate members and non-members\n",
    "members = labels == 1\n",
    "non_members = labels == 0\n",
    "\n",
    "# Plot noise magnitude per point for different T values\n",
    "plt.figure(figsize=(10, 6))\n",
    "for T, noise in saved_outputs.items():\n",
    "    noise_magnitude = noise.norm(dim=1)  # Compute magnitude of noise per point\n",
    "    plt.plot([T] * len(noise_magnitude[members]), noise_magnitude[members], 'bo', alpha=0.02, label='Members' if T == 0 else \"\")\n",
    "    plt.plot([T] * len(noise_magnitude[non_members]), noise_magnitude[non_members], 'ro', alpha=0.02, label='Non-Members' if T == 0 else \"\")\n",
    "\n",
    "plt.xlabel(\"T values\")\n",
    "plt.ylabel(\"Noise Magnitude\")\n",
    "plt.title(\"Noise Magnitude per Point Over Different T values\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute distances for T = 0 vs 1000 and T = 0 vs 200\n",
    "distances_0_1999 = distance(saved_outputs[0], saved_outputs[1999])\n",
    "distances_0_1800= distance(saved_outputs[0], saved_outputs[1800])\n",
    "distances_0_1600 = distance(saved_outputs[0], saved_outputs[1600])\n",
    "distances_0_1400 = distance(saved_outputs[0], saved_outputs[1400])\n",
    "distances_0_1200 = distance(saved_outputs[0], saved_outputs[1200])\n",
    "distances_0_1000 = distance(saved_outputs[0], saved_outputs[1000])\n",
    "distances_0_800 = distance(saved_outputs[0], saved_outputs[800])\n",
    "distances_0_600 = distance(saved_outputs[0], saved_outputs[600])\n",
    "distances_0_400 = distance(saved_outputs[0], saved_outputs[400])\n",
    "distances_0_200 = distance(saved_outputs[0], saved_outputs[200])\n",
    "\n",
    "# Separate distances for members and non-members\n",
    "dist_0_1000_members = distances_0_1000[members]\n",
    "dist_0_1000_non_members = distances_0_1000[non_members]\n",
    "\n",
    "dist_0_200_members = distances_0_400[members]\n",
    "dist_0_200_non_members = distances_0_400[non_members]\n",
    "\n",
    "# Plot histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].hist(dist_0_1000_members, bins=50, alpha=0.6, color='b', label=\"Members\")\n",
    "axes[0].hist(dist_0_1000_non_members, bins=50, alpha=0.6, color='r', label=\"Non-Members\")\n",
    "axes[0].set_title(\"Distance between T=0 and T=1999\")\n",
    "axes[0].set_xlabel(\"Distance\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(dist_0_200_members, bins=50, alpha=0.6, color='b', label=\"Members\")\n",
    "axes[1].hist(dist_0_200_non_members, bins=50, alpha=0.6, color='r', label=\"Non-Members\")\n",
    "axes[1].set_title(\"Distance between T=0 and T=400\")\n",
    "axes[1].set_xlabel(\"Distance\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryROC\n",
    "\n",
    "# Normalize distances to [0,1] range for probability scores\n",
    "def normalize_scores(member_distances, nonmember_distances):\n",
    "    max_dist = max(member_distances.max().item(), nonmember_distances.max().item())\n",
    "    member_probs = 1 - (member_distances / max_dist)\n",
    "    nonmember_probs = 1 - (nonmember_distances / max_dist)\n",
    "    return member_probs, nonmember_probs\n",
    "\n",
    "# Compute scores\n",
    "member_scores, nonmember_scores = normalize_scores(distances_0_400[members], distances_0_400[non_members])\n",
    "\n",
    "# Create labels (1 for members, 0 for non-members)\n",
    "labels = torch.cat([torch.ones_like(member_scores), torch.zeros_like(nonmember_scores)]).long()\n",
    "scores = torch.cat([member_scores, nonmember_scores])\n",
    "\n",
    "# Compute predictions\n",
    "predictions = (scores).long()\n",
    "\n",
    "# Save predictions and scores to CSV\n",
    "df = pd.DataFrame({\n",
    "    'score': scores.numpy(),\n",
    "})\n",
    "df.to_csv(os.path.join(path, \"predictions.csv\"), index=False, header=False)\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = BinaryAUROC()(scores, labels).item()\n",
    "\n",
    "# Compute ROC curve\n",
    "roc = BinaryROC()(scores, labels)\n",
    "fpr, tpr, _ = roc  # Unpack outputs\n",
    "\n",
    "# Extract TPR at 10% FPR\n",
    "fpr_threshold = 0.1\n",
    "tpr_at_1_fpr = tpr[(fpr < fpr_threshold).sum() - 1].item()\n",
    "\n",
    "# Print results\n",
    "print(f\"AUROC: {auroc:.4f}\")\n",
    "print(f\"TPR at 10% FPR: {tpr_at_1_fpr:.4f}\")\n",
    "print(\"Predictions saved to predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "Ensure that you have installed the proper dependenices to run the notebook. The environment installation instructions are available [here](https://github.com/VectorInstitute/MIDSTModels/tree/main/starter_kits). Now that we have verfied we have the proper packages installed, lets import them and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd starter_kits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_challenge_points, get_challenge_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "\n",
    "TABDDPM_DATA_DIR = \"tabddpm_white_box\"\n",
    "TABSYN_DATA_DIR = \"tabsyn_white_box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(base_dir, attacker_name=\"PIA\", attack_num=30, interval=10, lp=3):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # logger.addHandler(RichHandler())\n",
    "\n",
    "    logger.info(\"loading the attacked model...\")\n",
    "\n",
    "    # Initialize attacker\n",
    "    phases = [\"train\"]\n",
    "    # phases = [\"dev\", \"final\"]\n",
    "    \n",
    "    logger.info(\"attack start...\")\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            if \"30\" not in str(path):\n",
    "                continue\n",
    "\n",
    "            model = tabddpm_whitebox_load_pretrained(path)\n",
    "            attacker = ATTACKERS[attacker_name](\n",
    "                torch.from_numpy(np.linspace(FLAGS.beta_1, FLAGS.beta_T, FLAGS.T)).to(DEVICE), interval, attack_num, EpsGetter(model), lp=lp)\n",
    "\n",
    "            challenge_points = get_challenge_points(path)\n",
    "            challenge_labels = get_challenge_labels(path)\n",
    "            raw_predictions = torch.stack([attacker(cp.to(DEVICE).float()) for cp in challenge_points])\n",
    "            raw_predictions_means = raw_predictions.mean(dim=1).cpu().detach().numpy()\n",
    "            challenge_labels_np = challenge_labels.values.squeeze()\n",
    "\n",
    "            non_member_distances = raw_predictions_means[challenge_labels_np == 0]\n",
    "            member_distances = raw_predictions_means[challenge_labels_np == 1]\n",
    "\n",
    "            # Create figure with three subplots\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15), height_ratios=[1, 1, 1.5])\n",
    "            \n",
    "            # Plot 1: Full distribution\n",
    "            bins = np.linspace(min(raw_predictions_means), max(raw_predictions_means), 30)\n",
    "            ax1.hist(non_member_distances, bins=bins, alpha=0.6, \n",
    "                    label=f'Non-member (n={len(non_member_distances)})', \n",
    "                    color='blue')\n",
    "            ax1.hist(member_distances, bins=bins, alpha=0.6,\n",
    "                    label=f'Member (n={len(member_distances)})', \n",
    "                    color='red')\n",
    "            \n",
    "            ax1.set_xlabel('Distance')\n",
    "            ax1.set_ylabel('Count')\n",
    "            ax1.set_title('Full Distribution of Distances')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "\n",
    "            # First zoom: Find the densest region\n",
    "            all_data = np.concatenate([member_distances, non_member_distances])\n",
    "            Q1 = np.percentile(all_data, 25)\n",
    "            Q3 = np.percentile(all_data, 75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 0.5 * IQR\n",
    "            upper_bound = Q3 + 0.5 * IQR\n",
    "\n",
    "            # Filter data for first zoom\n",
    "            non_member_filtered = non_member_distances[\n",
    "                (non_member_distances >= lower_bound) & \n",
    "                (non_member_distances <= upper_bound)\n",
    "            ]\n",
    "            member_filtered = member_distances[\n",
    "                (member_distances >= lower_bound) & \n",
    "                (member_distances <= upper_bound)\n",
    "            ]\n",
    "\n",
    "            # Plot 2: First zoom level\n",
    "            detailed_bins = np.linspace(lower_bound, upper_bound, 50)\n",
    "            ax2.hist(non_member_filtered, bins=detailed_bins, alpha=0.6,\n",
    "                    label=f'Non-member (n={len(non_member_filtered)})', \n",
    "                    color='blue')\n",
    "            ax2.hist(member_filtered, bins=detailed_bins, alpha=0.6,\n",
    "                    label=f'Member (n={len(member_filtered)})', \n",
    "                    color='red')\n",
    "            \n",
    "            ax2.set_xlabel('Distance')\n",
    "            ax2.set_ylabel('Count')\n",
    "            ax2.set_title('First Zoom Level\\n'\n",
    "                        f'(Range: {lower_bound:.2f} to {upper_bound:.2f})')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "\n",
    "            # Second zoom: Find the even denser region\n",
    "            filtered_data = np.concatenate([member_filtered, non_member_filtered])\n",
    "            Q1_filtered = np.percentile(filtered_data, 25)\n",
    "            Q3_filtered = np.percentile(filtered_data, 75)\n",
    "            IQR_filtered = Q3_filtered - Q1_filtered\n",
    "            lower_bound_filtered = Q1_filtered - 0.25 * IQR_filtered  # Using tighter bounds\n",
    "            upper_bound_filtered = Q3_filtered + 0.25 * IQR_filtered\n",
    "\n",
    "            # Filter data for second zoom\n",
    "            non_member_filtered_2 = non_member_filtered[\n",
    "                (non_member_filtered >= lower_bound_filtered) & \n",
    "                (non_member_filtered <= upper_bound_filtered)\n",
    "            ]\n",
    "            member_filtered_2 = member_filtered[\n",
    "                (member_filtered >= lower_bound_filtered) & \n",
    "                (member_filtered <= upper_bound_filtered)\n",
    "            ]\n",
    "\n",
    "            # Plot 3: Second zoom level with very fine bins\n",
    "            very_detailed_bins = np.linspace(lower_bound_filtered, upper_bound_filtered, 100)\n",
    "            ax3.hist(non_member_filtered_2, bins=very_detailed_bins, alpha=0.6,\n",
    "                    label=f'Non-member (n={len(non_member_filtered_2)})', \n",
    "                    color='blue')\n",
    "            ax3.hist(member_filtered_2, bins=very_detailed_bins, alpha=0.6,\n",
    "                    label=f'Member (n={len(member_filtered_2)})', \n",
    "                    color='red')\n",
    "            \n",
    "            ax3.set_xlabel('Distance')\n",
    "            ax3.set_ylabel('Count')\n",
    "            ax3.set_title('Second Zoom Level (Finest Detail)\\n'\n",
    "                        f'(Range: {lower_bound_filtered:.2f} to {upper_bound_filtered:.2f})')\n",
    "            ax3.legend()\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "\n",
    "            # Add statistical information for the finest zoom level\n",
    "            stats_text = (\n",
    "                f'Dense Region Stats:\\n'\n",
    "                f'Non-member:\\n'\n",
    "                f'  Mean: {np.mean(non_member_filtered_2):.3f}\\n'\n",
    "                f'  Std: {np.std(non_member_filtered_2):.3f}\\n'\n",
    "                f'Member:\\n'\n",
    "                f'  Mean: {np.mean(member_filtered_2):.3f}\\n'\n",
    "                f'  Std: {np.std(member_filtered_2):.3f}'\n",
    "            )\n",
    "            ax3.text(0.02, 0.98, stats_text, \n",
    "                    transform=ax3.transAxes,\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(path, f\"distance_distribution_T={interval}_lp={lp}.png\"), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            # Save detailed statistics for all zoom levels\n",
    "            stats_summary = pd.DataFrame({\n",
    "                'Metric': ['Full Mean', 'Full Std', \n",
    "                        'First Zoom Mean', 'First Zoom Std',\n",
    "                        'Second Zoom Mean', 'Second Zoom Std',\n",
    "                        'Points in Densest Region', 'Total Points'],\n",
    "                'Member': [\n",
    "                    member_distances.mean(),\n",
    "                    member_distances.std(),\n",
    "                    member_filtered.mean(),\n",
    "                    member_filtered.std(),\n",
    "                    member_filtered_2.mean(),\n",
    "                    member_filtered_2.std(),\n",
    "                    len(member_filtered_2),\n",
    "                    len(member_distances)\n",
    "                ],\n",
    "                'Non-member': [\n",
    "                    non_member_distances.mean(),\n",
    "                    non_member_distances.std(),\n",
    "                    non_member_filtered.mean(),\n",
    "                    non_member_filtered.std(),\n",
    "                    non_member_filtered_2.mean(),\n",
    "                    non_member_filtered_2.std(),\n",
    "                    len(non_member_filtered_2),\n",
    "                    len(non_member_distances)\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            stats_summary.to_csv(os.path.join(path, f\"detailed_statistics_T={interval}_lp={lp}.csv\"), index=False)\n",
    "\n",
    "            # Continue with the original prediction code\n",
    "            normalized_preds = []\n",
    "            for pred_batch in raw_predictions:\n",
    "                binary_preds = (pred_batch <= 1000000).float()\n",
    "                normalized_preds.append(binary_preds)\n",
    "\n",
    "            final_predictions = torch.stack(normalized_preds)\n",
    "            predictions_cpu = final_predictions.cpu().detach().numpy()\n",
    "\n",
    "            with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                for value in predictions_cpu.squeeze():\n",
    "                    writer.writerow([value])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack(base_dir=\"tabddpm_white_box\",\n",
    "        attacker_name=\"PIAN\",\n",
    "        attack_num=3,\n",
    "        interval=200,\n",
    "        lp=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "def safe_load_data(filepath: str, is_prediction: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Safely load data from CSV files with error handling and debugging.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        is_prediction: Whether this is a prediction file (True) or label file (False)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Loaded and validated data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if is_prediction:\n",
    "            # Read the file line by line and parse each array\n",
    "            predictions = []\n",
    "            with open(filepath, 'r') as f:\n",
    "                for line in f:\n",
    "                    # Remove brackets and split by spaces\n",
    "                    clean_line = line.strip().replace('[', '').replace(']', '')\n",
    "                    # Convert space-separated strings to floats\n",
    "                    row = np.array([float(x) for x in clean_line.split()])\n",
    "                    predictions.append(row)\n",
    "            return np.array(predictions)\n",
    "        else:\n",
    "            # For label files, skip header and use numpy\n",
    "            return np.loadtxt(filepath, skiprows=1)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {str(e)}\")\n",
    "        print(f\"File contents (first few lines):\")\n",
    "        with open(filepath, 'r') as f:\n",
    "            print(f.read(500))\n",
    "        raise\n",
    "\n",
    "def get_tpr_at_fpr(y_true: np.ndarray, y_score: np.ndarray, target_fpr: float = 0.1) -> float:\n",
    "    \"\"\"Calculate TPR at a specific FPR threshold.\"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(y_true, np.ndarray) or not isinstance(y_score, np.ndarray):\n",
    "        raise TypeError(\"Inputs must be numpy arrays\")\n",
    "    if y_true.shape != y_score.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true {y_true.shape} != y_score {y_score.shape}\")\n",
    "    \n",
    "    # Sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n",
    "    y_score = y_score[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "    \n",
    "    n_neg = np.sum(y_true == 0)\n",
    "    n_pos = np.sum(y_true == 1)\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if n_neg == 0 or n_pos == 0:\n",
    "        print(\"Warning: Found no positive or negative samples\")\n",
    "        return 0.0\n",
    "        \n",
    "    tpr = np.cumsum(y_true) / n_pos\n",
    "    fpr = np.cumsum(1 - y_true) / n_neg\n",
    "    \n",
    "    for i in range(len(fpr)):\n",
    "        if fpr[i] >= target_fpr:\n",
    "            return tpr[i]\n",
    "    return 1.0\n",
    "\n",
    "def evaluate_membership_inference(base_dirs: List[str]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate membership inference attack results across multiple directories.\n",
    "    \n",
    "    Args:\n",
    "        base_dirs: List of base directories containing prediction files\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_tpr_at_fpr, best_auc)\n",
    "    \"\"\"\n",
    "    tpr_at_fpr_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    for base_dir in base_dirs:\n",
    "        predictions = []\n",
    "        solutions = []\n",
    "        root = os.path.join(base_dir, \"train\")\n",
    "        \n",
    "        if not os.path.exists(root):\n",
    "            print(f\"Warning: Directory not found: {root}\")\n",
    "            continue\n",
    "            \n",
    "        model_folders = sorted(os.listdir(root), key=lambda d: int(d.split('_')[1]))\n",
    "        if not model_folders:\n",
    "            print(f\"Warning: No model folders found in {root}\")\n",
    "            continue\n",
    "        \n",
    "        # Load and process all predictions and solutions\n",
    "        for model_folder in model_folders:\n",
    "            path = os.path.join(root, model_folder)\n",
    "            pred_path = os.path.join(path, \"prediction.csv\")\n",
    "            label_path = os.path.join(path, \"challenge_label.csv\")\n",
    "            \n",
    "            if not (os.path.exists(pred_path) and os.path.exists(label_path)):\n",
    "                print(f\"Warning: Missing files in {path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Load predictions\n",
    "                pred = safe_load_data(pred_path, is_prediction=True)\n",
    "                predictions.append(pred)\n",
    "                \n",
    "                # Load ground truth\n",
    "                solution = safe_load_data(label_path, is_prediction=False)\n",
    "                if solution.ndim == 0:\n",
    "                    solution = solution.reshape(1)\n",
    "                solutions.append(solution)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing folder {model_folder}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not predictions or not solutions:\n",
    "            print(f\"Warning: No valid data found in {base_dir}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Concatenate all predictions and solutions\n",
    "            predictions = np.concatenate(predictions)\n",
    "            solutions = np.concatenate(solutions)\n",
    "            \n",
    "            print(f\"\\nData shapes for {os.path.basename(base_dir)}:\")\n",
    "            print(f\"Predictions shape: {predictions.shape}\")\n",
    "            print(f\"Solutions shape: {solutions.shape}\")\n",
    "            \n",
    "            # Calculate metrics for each attacker's predictions\n",
    "            num_attackers = predictions.shape[1]\n",
    "            for attacker_idx in range(num_attackers):\n",
    "                attacker_preds = predictions[:, attacker_idx]\n",
    "                \n",
    "                # Basic data validation\n",
    "                if np.any(np.isnan(attacker_preds)):\n",
    "                    print(f\"Warning: NaN values found in predictions for attacker {attacker_idx}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate metrics\n",
    "                tpr_at_fpr = get_tpr_at_fpr(solutions, attacker_preds)\n",
    "                tpr_at_fpr_list.append(tpr_at_fpr)\n",
    "                \n",
    "                try:\n",
    "                    auc = roc_auc_score(solutions, attacker_preds)\n",
    "                    auc_list.append(auc)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Warning: Could not calculate AUC for attacker {attacker_idx}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"{os.path.basename(base_dir)} Attacker {attacker_idx + 1}:\")\n",
    "                print(f\"  TPR at FPR==10%: {tpr_at_fpr:.4f}\")\n",
    "                print(f\"  AUC: {auc:.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing directory {base_dir}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Get best scores\n",
    "    final_tpr_at_fpr = max(tpr_at_fpr_list) if tpr_at_fpr_list else 0.0\n",
    "    final_auc = max(auc_list) if auc_list else 0.0\n",
    "    \n",
    "    print(f\"\\nBest scores across all attackers:\")\n",
    "    print(f\"Final Train Attack TPR at FPR==10%: {final_tpr_at_fpr:.4f}\")\n",
    "    print(f\"Final Train Attack AUC: {final_auc:.4f}\")\n",
    "    \n",
    "    return final_tpr_at_fpr, final_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs = [TABDDPM_DATA_DIR]\n",
    "final_tpr, final_auc = evaluate_membership_inference(base_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench. Importantly, we create a single zip file for dev and final. The structure of the submission is as follows:\n",
    "\n",
    "```\n",
    " root_folder\n",
    "     tabsyn_white_box\n",
    "        dev\n",
    "           tabsyn_#\n",
    "               prediction.csv\n",
    "        final\n",
    "            tabsyn_#\n",
    "                prediction.csv\n",
    "     tabddpm_white_box\n",
    "         dev \n",
    "            tabddpm_#\n",
    "                prediction.csv\n",
    "         final \n",
    "             tabddpm_# \n",
    "                 prediction.csv\n",
    "```\n",
    "**Note:** The `root_folder` can have any name but it is important all of the subdirectories follow the above structure and naming conventions. \n",
    "\n",
    "If a participant is looking to submit an attack for only one of TabSyn and TabDDPM, they can simply omit the other directory (ie `tabddpm_white_box` or `tabsyn_white_box` from the root_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_numpy_array(array_str):\n",
    "    \"\"\"Fix NumPy-style array formatting and convert it to a Python list.\"\"\"\n",
    "    array_str = array_str.strip()  # Remove leading/trailing spaces\n",
    "    array_str = re.sub(r'\\s+', ',', array_str)  # Replace spaces with commas\n",
    "    array_str = array_str.replace(\"[,\", \"[\").replace(\",]\", \"]\")  # Fix misplaced commas\n",
    "    return eval(array_str)  # Convert string to list\n",
    "\n",
    "with zipfile.ZipFile(\"white_box_single_table_submission.zip\", 'w') as zipf:\n",
    "    for phase in [\"dev\", \"final\"]:\n",
    "        for base_dir in [TABDDPM_DATA_DIR]:\n",
    "            root = os.path.join(base_dir, phase)\n",
    "            for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                if not os.path.isdir(path): \n",
    "                    continue\n",
    "\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    # Load CSV\n",
    "                    df = pd.read_csv(file, header=None)\n",
    "\n",
    "                    # Convert NumPy-style arrays to proper lists\n",
    "                    df = df[0].apply(lambda x: parse_numpy_array(x) if isinstance(x, str) else x)\n",
    "\n",
    "                    # Compute mean for each row\n",
    "                    df_mean = df.apply(lambda x: np.mean(x) if isinstance(x, list) else x)\n",
    "                    file = os.path.join(path, \"prediction.csv\")\n",
    "                    # # Save the new CSV\n",
    "                    # df_mean.to_csv(file, index=False, header=False)\n",
    "\n",
    "                    # Add to ZIP\n",
    "                    arcname = os.path.relpath(file, os.path.dirname(base_dir))\n",
    "                    zipf.write(file, arcname=arcname)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`predictions.csv` not found in {path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated white_box_single_table_submission.zip can be directly submitted to the dev phase in the CodaBench UI. Although this submission contains your predictions for both the dev and final set, you will only receive feedback on your predictions for the dev phase. The predictions for the final phase will be evaluated once the competiton ends using the most recent submission to the dev phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
